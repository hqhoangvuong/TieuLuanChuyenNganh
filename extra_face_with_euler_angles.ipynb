{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "import urllib\n",
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_threshold = 0.4\n",
    "color = (0, 0, 255)\n",
    "ctx_id = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('videos/video1.mp4')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 16, 8] {'32': {'SCALES': (32, 16), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '16': {'SCALES': (8, 4), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '8': {'SCALES': (2, 1), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}}\n",
      "use_landmarks True\n"
     ]
    }
   ],
   "source": [
    "model = insightface.app.FaceAnalysis()\n",
    "model.prepare(ctx_id = ctx_id, nms=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_rotation_matrix(R) :\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotation_vector_to_euler_angles(rotation_vector) :\n",
    "    R, _ = cv2.Rodrigues(rotation_vector)\n",
    "    \n",
    "    if not is_rotation_matrix(R):\n",
    "        return\n",
    "    \n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.rad2deg(np.array([x, y, z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chin_calc(bbox, fivepointlandmarks):\n",
    "    p1 = np.asarray([bbox[2], bbox[3]])\n",
    "    p2 = np.asarray([bbox[0], bbox[3]])\n",
    "    p3 = np.asarray([int((fivepointlandmarks[6] + fivepointlandmarks[8]) / 2), int((fivepointlandmarks[7] + fivepointlandmarks[9]) / 2)])\n",
    "    chindistfromp3 = int(linalg.norm(np.cross(p2 - p1, p1 - p3)) / linalg.norm(p2 - p1))\n",
    "    chin = [p3[0], p3[1] + chindistfromp3]\n",
    "\n",
    "    # Return a 2-D point represent for the chin of the given face\n",
    "    return chin\n",
    "\n",
    "def six_point_of_landmarks(bbox, fivepointlandmarks):\n",
    "    pchin = chin_calc(bbox, fivepointlandmarks)\n",
    "\n",
    "    image_points = np.array([\n",
    "                            (fivepointlandmarks[4], fivepointlandmarks[5]),     # Nose tip\n",
    "                            (pchin[0], pchin[1])                          ,     # Chin\n",
    "                            (fivepointlandmarks[0], fivepointlandmarks[1]),     # Left eye left corner\n",
    "                            (fivepointlandmarks[2], fivepointlandmarks[3]),     # Right eye right corne\n",
    "                            (fivepointlandmarks[6], fivepointlandmarks[7]),     # Left Mouth corner\n",
    "                            (fivepointlandmarks[8], fivepointlandmarks[9])      # Right mouth corner\n",
    "                        ], dtype=\"double\")\n",
    "    return image_points\n",
    "\n",
    "def est_head_pose(face, imsize):\n",
    "    bbox = face.bbox.astype(np.int).flatten()\n",
    "    fivepointlandmarks = face.landmark.astype(np.int).flatten()\n",
    "    image_points = six_point_of_landmarks(bbox, fivepointlandmarks)\n",
    "\n",
    "    # 3D model points. \n",
    "    model_points = np.array([\n",
    "                                (0.0, 0.0, 0.0),             # Nose tip\n",
    "                                (0.0, -330.0, -65.0),        # Chin\n",
    "                                (-210.0, 170.0, -135.0),     # Left eye left corner\n",
    "                                (210.0, 170.0, -135.0),      # Right eye right corne\n",
    "                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                                (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                            ])\n",
    "    \n",
    "    # Camera internals\n",
    "    focal_length = imsize[1]\n",
    "    center = (imsize[1]/2, imsize[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                            [[focal_length, 0, center[0]],\n",
    "                            [0, focal_length, center[1]],\n",
    "                            [0, 0, 1]], dtype = \"double\"\n",
    "                            )\n",
    "    \n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, \n",
    "                                                                  image_points, \n",
    "                                                                  camera_matrix, \n",
    "                                                                  dist_coeffs, \n",
    "                                                                  flags=cv2.cv2.SOLVEPNP_ITERATIVE)\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), \n",
    "                                                                rotation_vector, \n",
    "                                                                translation_vector, \n",
    "                                                                camera_matrix, \n",
    "                                                                dist_coeffs)\n",
    "\n",
    "    p1 = (int(image_points[0][0]), int(image_points[0][1]))\n",
    "    p2 = (int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "    \n",
    "    euler_angles = rotation_vector_to_euler_angles(rotation_vector)\n",
    "\n",
    "    # return a line that point out the current pose of the head\n",
    "    return p1, p2, bbox, euler_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_filter(raw_euler_angles):\n",
    "    roll = False\n",
    "    pitch = False\n",
    "    yaw = False\n",
    "    \n",
    "    euler_angles = np.absolute(raw_euler_angles.astype(int))\n",
    "    \n",
    "    if (170 <= euler_angles[0] and euler_angles[0] <= 180) or (0 <= euler_angles[0] and euler_angles[0] <= 4):\n",
    "        roll = True\n",
    "    \n",
    "    if (170 <= euler_angles[2] and euler_angles[2] <= 180) or (0 <= euler_angles[2] and euler_angles[2] <= 4):\n",
    "        yaw = True\n",
    "        \n",
    "    if 30 <= euler_angles[1] and euler_angles[1] <= 55:\n",
    "        pitch = True\n",
    "    return roll and pitch and yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_face(face, index):\n",
    "    cv2.imwrite('filtered_faces/FaceNo' + str(index) + '.png', face)\n",
    "    \n",
    "def save_vector(vector, index):\n",
    "    vector.tofile('filtered_faces/VectorNo' + str(index) + '.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b47634436093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuler_angles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest_head_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/insightface/app/face_analysis.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, img, det_thresh, det_scale, max_num)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdet_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/insightface/model_zoo/face_detection.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, threshold, scale)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m               \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_idx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_anchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stride%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1994\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1997\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "faceNo = 0\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret is True:\n",
    "        faces = model.get(frame)\n",
    "        for idx, face in enumerate(faces):\n",
    "            p1, p2, bbox, euler_angles = est_head_pose(face, frame.shape)\n",
    "            if face_filter(euler_angles):\n",
    "                embedding = face.embedding.astype(np.float).flatten()\n",
    "                cropped_face = frame[bbox[1] : bbox[3], bbox[0] :bbox[2]]\n",
    "                save_face(cropped_face, faceNo)\n",
    "                save_vector(embedding, faceNo)\n",
    "                faceNo += 1\n",
    "                print(faceNo)\n",
    "        clear_output(wait=True)\n",
    "cap.release()\n",
    "print('Render completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
